{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/big/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
      "\u001b[K     |████████████████████████████████| 500 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\"\n",
      "  Downloading numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.1 MB 714 kB/s eta 0:00:01    |██████████████████▍             | 9.8 MB 6.2 MB/s eta 0:00:02     |█████████████████████▎          | 11.4 MB 6.2 MB/s eta 0:00:01     |███████████████████████████     | 14.4 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/home/big/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed numpy-1.23.2 pandas-1.4.4 pytz-2022.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/big/.local/lib/python3.8/site-packages (1.23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation - Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실행 여러 줄 하게 해주는 코드\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Transformation\n",
    "\n",
    "-  데이터를 가공하기 위한 논리적 실행계획\n",
    "-  기존의 RDD에 연산이 반영된 새로운 RDD를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation 메서드\n",
    "\n",
    "1. filter()\n",
    "2. map()\n",
    "3. flatMap()\n",
    "4. distinct()\n",
    "5. zip()\n",
    "6. join()\n",
    "6. reduceByKey()\n",
    "7. mapValues()\n",
    "8. sortBy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['하명도 스파크 50', '홍길동 스파크 80', '임꺽정 스파크 60']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['홍길동 스파크 80']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "# filter()\n",
    "# 조건에 맞는 데이터만\n",
    "score_rdd.filter(lambda e : '스파크' in e).collect()\n",
    "score_rdd.filter(lambda e : '스파크' in e).filter(lambda e :'홍길' in e).collect()\n",
    "type(score_rdd.filter(lambda e : '스파크' in e)) #결과 : rdd\n",
    "\n",
    "#문제 생기면 최종 rdd 실행할 수 있어서 회복 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map()\n",
    "# 각각의 요소에 적용\n",
    "data = [1,3,5,7,9]\n",
    "map_rdd=sc.parallelize(data)\n",
    "map_rdd.map(lambda e : e*2).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - flatMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 100, 4, 5, 6, 100, 7, 8, 9, 100]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatMap()\n",
    "#각각의 요소에 함수를 적용한 다음 평면화 시켜주는 함수\n",
    "nlist =[[1,2,3],[4,5,6],[7,8,9]]\n",
    "flat_rdd=sc.parallelize(nlist)\n",
    "def append_data(e): #넘어오는 인자가 list라서 아래에서 append 쓴다\n",
    "    e.append(100)\n",
    "    return e\n",
    "\n",
    "res = flat_rdd.flatMap(lambda e : append_data(e)).collect()\n",
    "len(res)\n",
    "res\n",
    "#[[1,2,3,100],[4,5,6,100],[7,8,9,100]] 로 나올것을 기대했으나  [1, 2, 3, 100, 4, 5, 6, 100, 7, 8, 9, 100] 이 나옴\n",
    "#flat 으로 평면화 해서 2차원은 1차원으로, 3차원은 2차원으로 바꿔서 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [[1, 2, 3,], 4, 5]\n",
    "# sc.parallelize(tmp).flatMap(lambda e : e ).collect() #에러남\n",
    "#첫번째 요소는 평면화 할게 있는데, 4,5 는 평면화 할게 없어서 에러 남\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['하',\n",
       " '명',\n",
       " '도',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '5',\n",
       " '0',\n",
       " '점',\n",
       " '홍',\n",
       " '길',\n",
       " '동',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '8',\n",
       " '0',\n",
       " '점',\n",
       " '임',\n",
       " '꺽',\n",
       " '정',\n",
       " ' ',\n",
       " '스',\n",
       " '파',\n",
       " '크',\n",
       " ' ',\n",
       " '6',\n",
       " '0',\n",
       " '점',\n",
       " '임',\n",
       " '요',\n",
       " '환',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '점',\n",
       " '홍',\n",
       " '진',\n",
       " '호',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '2',\n",
       " '2',\n",
       " '점',\n",
       " '홍',\n",
       " '진',\n",
       " '호',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '2',\n",
       " '2',\n",
       " '점',\n",
       " '이',\n",
       " '윤',\n",
       " '열',\n",
       " ' ',\n",
       " '텐',\n",
       " '서',\n",
       " '플',\n",
       " '로',\n",
       " '우',\n",
       " ' ',\n",
       " '9',\n",
       " '0',\n",
       " '점']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res =score_rdd.flatMap(lambda e : e + '점').collect()\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 : filter, map, flatMap \n",
    "\n",
    "nlist안의 요소들중 홀수인 요소만 추출하여 100을 곱하여 list로 반환하시오  \n",
    "\n",
    " - nlist = [[[1, 2], [3, 4, 5]],[[6, 7], [8, 9, 10, 11]],[[12,13,14,15], [16, 17]]]\n",
    "\n",
    " - 결과 : [100, 300, 500, 700, 900, 1100, 1300, 1500, 1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 300, 500, 700, 900, 1100, 1300, 1500, 1700]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = [[[1, 2], [3, 4, 5]],[[6, 7], [8, 9, 10, 11]],[[12,13,14,15], [16, 17]]]\n",
    "flat_rdd2=sc.parallelize(nlist)\n",
    "flat_rdd2.flatMap(lambda e:e).flatMap(lambda e:e).filter(lambda e : e%2 ==1).map(lambda e:e*100).collect()\n",
    "\n",
    "# nlist_rdd.filter(lambda x : if x%2 !=0).collect()\n",
    "# flat_rdd3.flatMap(lambda x : x*100, filter(lambda x : x%2 !=0)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 4, 3, 1, 5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['hello', '안녕', '반가워']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#중복제거\n",
    "nlist = [1, 2, 3, 1, 2, 3, 1, 2, 3 , 4, 5]\n",
    "distinct_rdd=sc.parallelize(nlist)\n",
    "distinct_rdd.distinct().collect()\n",
    "\n",
    "slist = ['안녕','반가워','hello','hello']\n",
    "distinct_rdd=sc.parallelize(slist)\n",
    "distinct_rdd.distinct().collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.api.java.JavaPairRDD@54da4353"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zip() : 두 rdd를 결합해 하나의 key-value 형태의 rdd(Pair RDD)로 생성\n",
    "foods = ['파스타','스테이크', '불고기', '비빔밥', '김치']\n",
    "category = ['양식', '양식', '한식', '한식', '한식']\n",
    "\n",
    "foods_rdd =sc.parallelize(foods)\n",
    "category_rdd=sc.parallelize(category)\n",
    "zip_rdd = category_rdd.zip(foods_rdd)\n",
    "zip_rdd #type 반환\n",
    "zip_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타'), ('양식', '스테이크'), ('한식', '불고기'), ('한식', '비빔밥'), ('한식', '김치')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuple의 list로 RDD 생성하면 Pair RDD 생성된다.\n",
    "tmp = list(map(lambda a,b : (a,b), category, foods ))\n",
    "# tmp\n",
    "tmp_rdd=sc.parallelize(tmp)\n",
    "tmp_rdd.collect()\n",
    "\n",
    "tmp = list(zip(category, foods))\n",
    "tmp_rdd=sc.parallelize(tmp)\n",
    "    \n",
    "# print('zip 결과')\n",
    "tmp_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - reduceByKey(), mapValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', '파스타,스테이크'), ('한식', '불고기,비빔밥,김치')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduceByKey, 키값을 기준으로 value값들을 연산\n",
    "#rdd 안에 있는걸 하나하나 다 찾아서 양식에 하나씩 모으고 한식에 하나씩 모아서 한 카테고리 안에서 키값이 모아져 있는애들과 다른 데이터들을 합치는 과정\n",
    "#불고기,비빔밥합쳐진거(a)에 김치(b) 가 되는 형식\n",
    "zip_rdd.reduceByKey(lambda a,b : a + ',' + b).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', '스테이크']), ('한식', ['불고기', '비빔밥', '김치'])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapValues, Pair RDD의 value들에 대해 map 연산을 수행\n",
    "#'' 로 구분\n",
    "res = zip_rdd.reduceByKey(lambda a,b : a + ',' + b) \\\n",
    "    .mapValues(lambda e : e.split(','))\n",
    "\n",
    "res.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - sortBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('한식', ['불고기', '비빔밥', '김치']), ('양식', ['파스타', '스테이크'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('한식', ['불고기', '비빔밥', '김치']), ('양식', ['파스타', '스테이크'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('한식', ['불고기', '비빔밥', '김치']), ('양식', ['파스타', '스테이크'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('양식', ['파스타', '스테이크']), ('한식', ['불고기', '비빔밥', '김치'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[0]:key 값 기준으로 정렬\n",
    "#[1] : value값 기준으로 정렬\n",
    "#위에서 res 정의해 줘야 함\n",
    "#키값으로 내림차순\n",
    "res.sortBy(lambda e : e[0], ascending = False).collect() # 'list' object has no attribute 'sortBy'\n",
    "\n",
    "res.sortBy(lambda e : e[1]).collect()#불고기, 파스타 중 불고기가 더 앞이니까 한식 먼저 나옴\n",
    "\n",
    "#메뉴 가짓수로 오름차순\n",
    "res.sortBy(lambda e : len(e[1]),ascending=False).collect()\n",
    "\n",
    "#응용: 2번 인덱스 기준으로 정렬\n",
    "res.sortBy(lambda e : e[1][1],ascending=False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 : distinct, zip, reduceByKey, sortBy \n",
    " - hdfs의 /score.txt 파일을 읽어와 RDD로 생성하시오\n",
    " - 각 과목별 명단을 추출하시오\n",
    " - 각 과목별 평균점수를 추출하시오\n",
    " - 이때 중복으로 들어간 홍진호의 데이터는 한번만 적용되도록 합니다.  \n",
    " \n",
    " \n",
    " \n",
    " - 결과 :  \n",
    " [('스파크', {'명단': ['하명도', '홍길동', '임꺽정']}), ('텐서플로우', {'명단': ['임요환', '홍진호', '이윤열']})]       \n",
    "  \n",
    " [('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스파크', {'평균점수': 63.333333333333336}), ('텐서플로우', {'평균점수': 70.66666666666667})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "base = score_rdd.distinct() \\\n",
    "    .map(lambda e : e.split(' '))\n",
    "base.collect()\n",
    "students = base.map(lambda e :(e[1],e[0]))\n",
    "students.collect()\n",
    "students = base.map(lambda e :(e[1],e[0])).reduceByKey(lambda a,b : a+','+b)\\\n",
    "                .mapValues(lambda e : e.split(',')).mapValues(lambda e : {'명단':e}) #리스트로, 명단 딕셔너리로\n",
    "students.collect()\n",
    "\n",
    "#split 없이 쓰기\n",
    "#[e[0]] :길이가 하나짜리인  리스트로 만들기\n",
    "# students = base.map(lambda e :(e[1],[e[0]])).reduceByKey(lambda a,b : a +b)\\\n",
    "#                 .mapValues(lambda e : {'명단':e}) #리스트로, 명단 딕셔너리로\n",
    "# students.collect()\n",
    "\n",
    "\n",
    "# # #2번 문제\n",
    "# #과목 먼저, 점수 뒤에\n",
    "score_avg = base.map(lambda e:(e[1],[int(e[2])])).reduceByKey(lambda a,b : a+b).mapValues(lambda e : {'평균점수': sum(e)/len(e)})\n",
    "score_avg.collect()\n",
    "score_avg.collect()\n",
    "\n",
    "# students=base.map()\n",
    "# base.collect()\n",
    "# score_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하명도 스파크 50',\n",
       " '홍길동 스파크 80',\n",
       " '이윤열 텐서플로우 90',\n",
       " '임요환 텐서플로우 100',\n",
       " '홍진호 텐서플로우 22',\n",
       " '임꺽정 스파크 60']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['하명도 스파크 50'], ['홍길동 스파크 80'], ['이윤열 텐서플로우 90'], ['임요환 텐서플로우 100'], ['홍진호 텐서플로우 22'], ['임꺽정 스파크 60']]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6 into shape (6,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m     17\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(a)\n\u001b[0;32m---> 18\u001b[0m A2\u001b[38;5;241m=\u001b[39m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m B\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     20\u001b[0m B\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 6 into shape (6,3)"
     ]
    }
   ],
   "source": [
    "\n",
    "#distinct 홍진호 날릴때, reducebykey, map 사용,mapvalues 사용, sortby는 쓰지 않음\n",
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "slist=score_rdd.collect()\n",
    "#중복제거\n",
    "distinct_rdd=sc.parallelize(slist)\n",
    "distinct_rdd2=distinct_rdd.distinct().collect()\n",
    "distinct_rdd2\n",
    "len(distinct_rdd2)\n",
    "\n",
    "#나누기\n",
    "# distinct_rdd2[0].split(\" \")\n",
    "a=[]\n",
    "for e in distinct_rdd2 :\n",
    "    result=e.split(\",\")\n",
    "    a.append(result)\n",
    "print(a)\n",
    "A = np.array(a)\n",
    "A2=A.reshape(6,3)\n",
    "B=A.T\n",
    "B \n",
    "# distinct_rdd.distinct().mapValues(lambda e : e.split(',')).collect()\n",
    "# distinct_rdd2.split(\",\")\n",
    "# pd.dataframe(distinct_rdd2)\n",
    "# dd=distinct_rdd2.split(',')\n",
    "# res=distinct_rdd2.reduceByKey(lambda a,b : a+','+b).collect()\n",
    "\n",
    "# distinct_rdd2.lambda e:e.split(' ').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['하명도 스파크 50', '홍길동 스파크 80', '이윤열 텐서플로우 90', '임요환 텐서플로우 100',\n",
       "        '홍진호 텐서플로우 22', '임꺽정 스파크 60']], dtype='<U13')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3929822564.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [15]\u001b[0;36m\u001b[0m\n\u001b[0;31m    distinct_rdd2.reduceByKey(lambda)\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "slist=score_rdd.collect()\n",
    "#1. 중복제거, split\n",
    "distinct_rdd=sc.parallelize(slist)\n",
    "distinct_rdd2=distinct_rdd.distinct().collect()\n",
    "# distinct_rdd.map(lambda x: (x.split(\",\")[1],x.split(\" \")[0]))\n",
    "# distinct_rdd2=distinct_rdd.distinct().map(lambda x: (x.split(\" \")[1],x.split(\",\")[0]))\n",
    "distinct_rdd2=distinct_rdd.distinct().map(lambda x: (x.split(\" \")))\n",
    "#2.flapMap\n",
    "distinct_rdd3=distinct_rdd2.flatMap(lambda e:e).collect()\n",
    "distinct_rdd2.reduceByKey(lambda)\n",
    "distinct_rdd2.collect()\n",
    "row=6\n",
    "col=3\n",
    "distinct_rdd4=[distinct_rdd3[r*col:(r+1)*col] for r in range(row)]\n",
    "print(distinct_rdd4)\n",
    "A = np.array(distinct_rdd4)\n",
    "\n",
    "B=A.T\n",
    "name = B[0]\n",
    "subject = B[1]\n",
    "score = B[2]\n",
    "\n",
    "name_rdd=sc.parallelize(name)\n",
    "subject_rdd=sc.parallelize(subject)\n",
    "zip_rdd=subject_rdd.zip(name_rdd)\n",
    "zip_rdd.collect()\n",
    "\n",
    "tmp=list(map(lambda a,b : (a,b), name,subject))\n",
    "tmp_rdd=sc.parallelize(tmp).collect()\n",
    "\n",
    "\n",
    "# zip_rdd.reduceByKey(lambda a,b : a+',' +b).collect()\n",
    "# # res = zip_rdd.reduceByKey(lambda a,b : a + ',' + b).collect()\n",
    "# # res = zip_rdd.reduceByKey(lambda a,b : a + ',' + b).mapValues(lambda e : e.split(','))\n",
    "\n",
    "# res.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하명도 스파크 50',\n",
       " '홍길동 스파크 80',\n",
       " '이윤열 텐서플로우 90',\n",
       " '임요환 텐서플로우 100',\n",
       " '홍진호 텐서플로우 22',\n",
       " '임꺽정 스파크 60']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "slist=score_rdd.collect()\n",
    "#1. 중복제거, split\n",
    "distinct_rdd=sc.parallelize(slist)\n",
    "distinct_rdd2=distinct_rdd.distinct().collect()\n",
    "distinct_rdd2\n",
    "\n",
    "# distinct_rdd2=distinct_rdd.distinct().map(lambda x: (x.split(\" \")[1],x.split(\" \")[0],x.split(\" \")[2]))\n",
    "# distinct_rdd2.collect()\n",
    "# distinct_rdd2=distinct_rdd.distinct().map(lambda x: (x.split(\" \")))\n",
    "#2.flapMap\n",
    "# distinct_rdd2.flatMap(lambda e:e).collect()\n",
    "# distinct_rdd2.reduceByKey(lambda)\n",
    "# distinct_rdd2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation - join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스파크', ({'명단': ['하명도', '홍길동', '임꺽정']}, {'평균점수': 63.333333333333336})),\n",
       " ('텐서플로우', ({'명단': ['홍진호', '임요환', '이윤열']}, {'평균점수': 70.66666666666667}))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#키를 기준으로 두 RDD를 결합\n",
    "res = students.join(score_avg)\n",
    "res.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스파크', {'명단': ['임꺽정', '하명도', '홍길동'], '평균점수': 63.333333333333336}),\n",
       " ('텐서플로우', {'명단': ['이윤열', '홍진호', '임요환'], '평균점수': 70.66666666666667})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[('스파크', {'명단': ['임꺽정', '하명도', '홍길동'], '평균점수': 63.333333333333336}),\n",
    "# ('텐서플로우', {'명단': ['이윤열', '홍진호', '임요환'], '평균점수': 70.66666666666667})]\n",
    "#위와 같이 딕셔너리를 하나로\n",
    "def tmp(e):\n",
    "    return dict(e[0], 평균점수=e[1]['평균점수'])\n",
    "res = students.join(score_avg) \\\n",
    "            .mapValues(lambda e : tmp(e))\n",
    "#[('스파크', {'명단': ['임꺽정', '하명도', '홍길동'], '평균점수': 63.333333333333336}),\n",
    "# ('텐서플로우', {'명단': ['이윤열', '홍진호', '임요환'], '평균점수': 70.66666666666667})]\n",
    "\n",
    "#2\n",
    "\n",
    "res = students.join(score_avg) \\\n",
    "            .mapValues(lambda e : dict(e[0], 평균점수=e[1]['평균점수']))\n",
    "\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Shuffle - 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스파크에서 연산은 단일 파티션에서 작동   \n",
    "\n",
    "\n",
    "- reduceByKey와 같이 특정 키에 매핑된 모든 값에 대한 연산을 수행하기 위해서는   \n",
    "  파티션에 흩어진 특정키에 해당하는 값을 하나의 파티션으로 모아 줄 필요가 있음  \n",
    "\n",
    "\n",
    "- 모든 키에 대한 모든 값을 찾기 위해 모든 파티션을 탐색하고, 해당하는 값들을 하나의 파티션으로 옮겨오는 과정을 셔플이라고 부른다.  \n",
    "\n",
    "\n",
    "- 디스크 IO 또는 네트워크 IO가 발생함으로 비용이 매우 비싼 작업  \n",
    "\n",
    "\n",
    "\n",
    "ex)   \n",
    "filter : 각 파티션에 있는 하나의 튜플에 대해 조건을 탐색하면 됨으로 셔플 발생 x  \n",
    "reduceByKey : 연산을 시작하기 위해서는 우선적으로 모든 파티션에 분산되어 있는 특정 키 값을 수집해야함으로 셔플 발생 \n",
    "- 셔플이 발생하는 함수들 :\n",
    " - subtractByKey\n",
    " - groupBy\n",
    " - foldByKey\n",
    " - reduceByKey\n",
    " - aggregateByKey\n",
    " - transformations of a join of any type\n",
    " - distinct\n",
    " - cogroup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shuffle](./img/shuffle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Action\n",
    "\n",
    "- transformation 연산을 통해 생성한 논리적 실행계획을 최적화 하여 연산을 수행. 빠른 연산이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Method\n",
    "\n",
    "1. collect()\n",
    "2. take()\n",
    "3. takeOrdered()\n",
    "4. top()\n",
    "5. countByValue()\n",
    "6. foreach()\n",
    "7. reduce()\n",
    "8. saveAsTextFile()\n",
    "9. max()\n",
    "10. min()\n",
    "11. mean()\n",
    "12. variance()\n",
    "13. stdev()\n",
    "14. stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하명도 스파크 50',\n",
       " '홍길동 스파크 80',\n",
       " '임꺽정 스파크 60',\n",
       " '임요환 텐서플로우 100',\n",
       " '홍진호 텐서플로우 22',\n",
       " '홍진호 텐서플로우 22',\n",
       " '이윤열 텐서플로우 90']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rdd에 있는 데이터를 리스트로 반환해주는 함수\n",
    "score_rdd=sc.textFile('/rdd/score.txt')\n",
    "score_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1,2,3,4,5]\n",
    "take_rdd =sc.parallelize(data)\n",
    "take_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - takeOrdered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[400, 100, 51, 32]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to_rdd.takeOrdered(꺼낼개수)\n",
    "data = [1,20,32,400,51,100,0.1]\n",
    "to_rdd = sc.parallelize(data)\n",
    "\n",
    "to_rdd.takeOrdered(4)\n",
    "to_rdd.takeOrdered(4, lambda e:-e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[400, 100, 51, 32, 20]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top N 개 내림차순으로 추출\n",
    "to_rdd.top(2)\n",
    "to_rdd.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 51, 400, 32, 20, 100, 1, 0.1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#문자-str은 첫 글짜끼리 비교\n",
    "data = [1,20,32,400,51,100,0.1,'a']\n",
    "to_rdd = sc.parallelize(data)\n",
    "to_rdd.top(8,key=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 3, 'b': 2, 'c': 1, 'd': 1})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#각 값의 개수를 반환해줌\n",
    "\n",
    "chars_rdd =sc.parallelize(['a','a','a','b','b','c','d'])\n",
    "chars_rdd.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "nums.reduce(lambda a,b : a+b)\n",
    "#((1+2)+3)+4...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - foreach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요소들 순차적으로 순회\n",
    "#안에 있는 요소들을 추가작업 할때 사용할 수 있음 -리턴값이 없음\n",
    "nums = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "nums = nums.foreach(lambda e:e*100)\n",
    "nums\n",
    "#foreach는 리턴 타입이 none 이다.\n",
    "type(nums) #결과 : NoneType\n",
    "\n",
    "# def f(x):ㅇ\n",
    "#     print(x)\n",
    "# nums.foreach(f)\n",
    "\n",
    "# def f(x): \n",
    "#     print(x)\n",
    "# nums=sc.parallelize([1, 2, 3, 4, 5]).foreach(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - saveAsTextFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#하둡에 저장\n",
    "\n",
    "score_rdd = sc.textFile(\"/rdd/score.txt\")\n",
    "base = score_rdd.distinct() \\\n",
    "    .map(lambda e : e.split(' '))\n",
    "students = base.map(lambda e :(e[1],e[0]))\n",
    "\n",
    "students = base.map(lambda e :(e[1],e[0])).reduceByKey(lambda a,b : a +',' +b)\\\n",
    "                .mapValues(lambda e : e.split(',')).mapValues(lambda e : {'명단':e})\n",
    "\n",
    "\n",
    "#split 없이 쓰기\n",
    "#[e[0]] :길이가 하나짜리인  리스트로 만들기\n",
    "students = base.map(lambda e :(e[1],[e[0]])).reduceByKey(lambda a,b : a +b)\\\n",
    "                .mapValues(lambda e : {'명단':e})\n",
    "\n",
    "#2번 문제\n",
    "#과목 먼저, 점수 뒤에\n",
    "score_avg = base.map(lambda e:(e[1],[int(e[2])])).reduceByKey(lambda a,b : a+b) \\\n",
    "                .mapValues(lambda e : {'평균점수': sum(e)/len(e)})\n",
    "\n",
    "\n",
    "\n",
    "#키를 기준으로 두 RDD를 결합\n",
    "res = students.join(score_avg)\n",
    "res.saveAsTextFile(\"/rdd/score_transform.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('스파크', ({'명단': ['하명도', '홍길동', '임꺽정']}, {'평균점수': 63.333333333333336}))\",\n",
       " \"('텐서플로우', ({'명단': ['임요환', '홍진호', '이윤열']}, {'평균점수': 70.66666666666667}))\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score_Transform 에 올라간거 확인-병렬처리로 빠르게 쓰려고 하는거라 파티션으로 나눠져서 올라감\n",
    "test = sc.textFile(\"/rdd/score_transform.txt\")\n",
    "test.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action - max, min, mean, variance, stdev, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 7, mean: 4.0, stdev: 2.0, max: 7, min: 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nums = sc.parallelize([1, 4, 2, 3, 7, 6, 5])\n",
    "nums.max()\n",
    "nums.min()\n",
    "nums.mean()\n",
    "nums.variance()\n",
    "nums.stdev()\n",
    "nums.stats() #요약정보 (count: 7, mean: 4.0, stdev: 2.0, max: 7, min: 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
